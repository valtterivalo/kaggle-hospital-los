# healthcare ai predictor - implementation roadmap

**Status**: âœ… COMPLETED (August 1, 2025)  
**Actual Development Time**: ~4 hours (vs 6 hours planned)

## development timeline (actual vs planned)

### phase 1: project setup and data exploration (1.5 hours)

#### environment setup (30 minutes)
```bash
# project initialization
mkdir healthcare-ai-predictor
cd healthcare-ai-predictor
git init

# backend setup
mkdir backend
cd backend
uv init --python 3.11
uv add fastapi uvicorn polars xgboost scikit-learn shap pydantic python-multipart
uv add --dev ruff pytest httpx

# frontend setup
cd ..
mkdir frontend
cd frontend
pnpm create next-app@latest . --typescript --tailwind --eslint --app
pnpm add @radix-ui/react-slot class-variance-authority clsx tailwind-merge lucide-react
npx shadcn-ui@latest init
npx shadcn-ui@latest add button input card form select
pnpm add recharts @types/recharts
```

#### dataset acquisition and initial eda (1 hour)
1. **download dataset**: acquire hospital length of stay dataset from kaggle
2. **data exploration**: create exploratory analysis notebook with polars
3. **data quality assessment**: identify missing values, outliers, data types
4. **feature analysis**: understand predictive features and target distribution
5. **initial preprocessing**: basic cleaning and feature engineering exploration

### phase 2: ml pipeline development (2 hours)

#### data processing pipeline (45 minutes)
```python
# data_service.py implementation
- load_raw_data(): polars lazy frame loading
- clean_data(): handle missing values, outliers
- engineer_features(): create derived features for better predictions
- split_data(): temporal or stratified splits for healthcare data
- validate_schema(): ensure data quality and consistency
```

#### model development (45 minutes)
```python
# ml_service.py implementation
- train_model(): xgboost with hyperparameter tuning
- evaluate_model(): comprehensive metrics and validation
- explain_predictions(): shap value calculations
- save_model(): model serialization with versioning
- load_model(): production model loading
```

#### api development (30 minutes)
```python
# fastapi endpoints
- POST /predict: single prediction with explanation
- POST /predict/batch: multiple predictions
- GET /data/summary: dataset statistics
- GET /health: service health check
- POST /data/query: llm-powered natural language queries
```

### phase 3: frontend development (1.5 hours)

#### core ui components (45 minutes)
```typescript
// component development
- PredictionForm: input form with validation
- ResultsDisplay: prediction results with explanations
- DataVisualization: charts and graphs using recharts
- Navigation: app layout and routing
- LoadingStates: proper loading and error handling
```

#### real-time features (45 minutes)
```typescript
// interactive features
- live prediction updates
- data exploration interface
- model explanation visualizations
- responsive design implementation
- error handling and user feedback
```

### phase 4: integration and deployment (1 hour)

#### docker containerization (30 minutes)
```dockerfile
# backend dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY . .
RUN uv pip install --system -r requirements.txt
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]

# frontend dockerfile
FROM node:18-alpine
WORKDIR /app
COPY . .
RUN pnpm install && pnpm build
CMD ["pnpm", "start"]

# docker-compose.yml
version: '3.8'
services:
  backend:
    build: ./backend
    ports: ["8000:8000"]
  frontend:
    build: ./frontend
    ports: ["3000:3000"]
    depends_on: [backend]
```

#### azure deployment (30 minutes)
```bash
# azure deployment
az login
az group create --name healthcare-ai --location northeurope
az containerapp up --name healthcare-predictor --source . --environment myenv
```

## detailed implementation steps

### step 1: backend foundation

#### 1.1 project structure creation
```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ api/
â”‚   â””â”€â”€ core/
â”œâ”€â”€ ml/
â”œâ”€â”€ data/
â”œâ”€â”€ tests/
â””â”€â”€ pyproject.toml
```

#### 1.2 fastapi application setup
```python
# app/main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.api import predictions, data, health

app = FastAPI(title="Healthcare AI Predictor", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(predictions.router, prefix="/api/predictions")
app.include_router(data.router, prefix="/api/data")
app.include_router(health.router, prefix="/api/health")
```

#### 1.3 data models definition
```python
# app/models/prediction.py
from pydantic import BaseModel, Field
from typing import List, Optional

class PatientInput(BaseModel):
    age: int = Field(..., ge=0, le=120)
    gender: str = Field(..., regex="^(Male|Female)$")
    admission_type: str
    medical_condition: str
    # additional fields based on dataset

class PredictionResponse(BaseModel):
    predicted_los: float
    confidence_interval: List[float]
    shap_values: dict
    explanation: str
```

### step 2: data processing implementation

#### 2.1 polars data pipeline
```python
# services/data_service.py
import polars as pl
from pathlib import Path

class DataService:
    def __init__(self, data_path: Path):
        self.data_path = data_path
        
    def load_raw_data(self) -> pl.LazyFrame:
        """Load raw healthcare data with lazy evaluation."""
        return pl.scan_csv(self.data_path / "hospital_los.csv")
    
    def preprocess_data(self, df: pl.LazyFrame) -> pl.LazyFrame:
        """Clean and engineer features."""
        return (
            df
            .with_columns([
                pl.col("Age").cast(pl.Int32),
                pl.col("Length of Stay").alias("los").cast(pl.Float32),
                # feature engineering transformations
            ])
            .filter(pl.col("los") > 0)
            .drop_nulls()
        )
```

#### 2.2 ml service implementation
```python
# services/ml_service.py
import joblib
import shap
from xgboost import XGBRegressor
from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_squared_error, r2_score

class MLService:
    def __init__(self):
        self.model = None
        self.explainer = None
        
    def train_model(self, X, y):
        """Train xgboost model with hyperparameter tuning."""
        self.model = XGBRegressor(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            random_state=42
        )
        self.model.fit(X, y)
        self.explainer = shap.TreeExplainer(self.model)
        
    def predict_with_explanation(self, X):
        """Generate predictions with shap explanations."""
        predictions = self.model.predict(X)
        shap_values = self.explainer.shap_values(X)
        return predictions, shap_values
```

### step 3: frontend implementation

#### 3.1 prediction form component
```typescript
// components/forms/PredictionForm.tsx
"use client"

import { useState } from 'react'
import { Button } from '@/components/ui/button'
import { Input } from '@/components/ui/input'
import { Card } from '@/components/ui/card'
import { Select } from '@/components/ui/select'

interface PredictionFormProps {
  onSubmit: (data: PatientData) => void
  loading: boolean
}

export function PredictionForm({ onSubmit, loading }: PredictionFormProps) {
  const [formData, setFormData] = useState<PatientData>({
    age: 0,
    gender: '',
    admission_type: '',
    medical_condition: ''
  })

  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault()
    onSubmit(formData)
  }

  return (
    <Card className="p-6">
      <form onSubmit={handleSubmit} className="space-y-4">
        <Input
          type="number"
          placeholder="Age"
          value={formData.age}
          onChange={(e) => setFormData(prev => ({ ...prev, age: parseInt(e.target.value) }))}
        />
        <Select
          value={formData.gender}
          onValueChange={(value) => setFormData(prev => ({ ...prev, gender: value }))}
        >
          <option value="Male">Male</option>
          <option value="Female">Female</option>
        </Select>
        <Button type="submit" disabled={loading}>
          {loading ? 'Predicting...' : 'Predict Length of Stay'}
        </Button>
      </form>
    </Card>
  )
}
```

#### 3.2 results visualization
```typescript
// components/charts/PredictionResults.tsx
import { Card } from '@/components/ui/card'
import { BarChart, Bar, XAxis, YAxis, ResponsiveContainer } from 'recharts'

interface ResultsProps {
  prediction: number
  shapValues: Record<string, number>
  explanation: string
}

export function PredictionResults({ prediction, shapValues, explanation }: ResultsProps) {
  const shapData = Object.entries(shapValues).map(([feature, value]) => ({
    feature,
    value: Math.abs(value),
    impact: value > 0 ? 'positive' : 'negative'
  }))

  return (
    <div className="space-y-6">
      <Card className="p-6">
        <h3 className="text-2xl font-bold">Predicted Length of Stay</h3>
        <p className="text-4xl text-blue-600">{prediction.toFixed(1)} days</p>
        <p className="text-gray-600 mt-2">{explanation}</p>
      </Card>
      
      <Card className="p-6">
        <h4 className="text-lg font-semibold mb-4">Feature Importance</h4>
        <ResponsiveContainer width="100%" height={300}>
          <BarChart data={shapData}>
            <XAxis dataKey="feature" />
            <YAxis />
            <Bar dataKey="value" fill="#3b82f6" />
          </BarChart>
        </ResponsiveContainer>
      </Card>
    </div>
  )
}
```

### step 4: advanced features

#### 4.1 llm integration for data querying
```python
# services/llm_service.py
import ollama
import polars as pl

class LLMService:
    def __init__(self, data_service: DataService):
        self.data_service = data_service
        
    async def natural_language_query(self, query: str) -> dict:
        """Process natural language queries about the data."""
        # convert query to sql/polars operations using llm
        prompt = f"""
        Given this healthcare dataset with columns: age, gender, admission_type, 
        medical_condition, length_of_stay, convert this query to polars code:
        
        Query: {query}
        
        Return only the polars code:
        """
        
        response = ollama.generate(model="llama2", prompt=prompt)
        # execute generated code safely and return results
        return {"query": query, "result": "processed_result"}
```

#### 4.2 real-time prediction streaming
```typescript
// hooks/useRealTimePredictions.ts
import { useState, useEffect } from 'react'

export function useRealTimePredictions() {
  const [predictions, setPredictions] = useState<Prediction[]>([])
  
  useEffect(() => {
    const ws = new WebSocket('ws://localhost:8000/ws/predictions')
    
    ws.onmessage = (event) => {
      const newPrediction = JSON.parse(event.data)
      setPredictions(prev => [...prev, newPrediction])
    }
    
    return () => ws.close()
  }, [])
  
  return predictions
}
```

## quality assurance checklist

### code quality
- [ ] all code passes ruff linting
- [ ] comprehensive docstrings for all functions
- [ ] type hints throughout python codebase
- [ ] typescript strict mode enabled
- [ ] proper error handling and logging

### functionality testing
- [ ] unit tests for ml pipeline
- [ ] api endpoint testing
- [ ] frontend component testing
- [ ] end-to-end prediction workflow
- [ ] data validation and edge cases

### performance optimization
- [ ] prediction response time < 1 second
- [ ] efficient data loading with polars lazy evaluation
- [ ] proper caching for frequently accessed data
- [ ] optimized bundle size for frontend
- [ ] database query optimization

### security considerations
- [ ] input validation for all user inputs
- [ ] proper cors configuration
- [ ] no sensitive data in logs
- [ ] secure api key management
- [ ] rate limiting implementation

### deployment readiness
- [ ] docker containers build successfully
- [ ] environment variables properly configured
- [ ] health checks implemented
- [ ] monitoring and logging setup
- [ ] azure deployment tested

## post-development enhancements

### immediate improvements
- add model retraining pipeline
- implement a/b testing for model versions
- enhanced data visualization dashboard
- batch prediction capabilities
- api documentation with swagger

### future roadmap
- multi-model ensemble predictions
- automated model monitoring and alerting
- integration with hospital information systems
- regulatory compliance features (gdpr, eu ai act)
- advanced anomaly detection capabilities

## âœ… implementation status

### completed features
- [x] Backend FastAPI application with proper structure
- [x] Synthetic healthcare dataset generation (10K records)
- [x] XGBoost ML model training and persistence
- [x] Real-time prediction API endpoints
- [x] Next.js frontend with shadcn/ui components
- [x] Patient information form with validation
- [x] Prediction results display with explanations
- [x] Error handling and loading states
- [x] CORS configuration for frontend integration

### simplified implementations
- [x] Basic feature engineering (age groups, categorical encoding)
- [x] Simple model training (no hyperparameter tuning)
- [x] Text-based explanations (no SHAP integration)
- [x] Random data splitting (no temporal splitting)
- [x] Eager evaluation data processing (simplified Polars usage)

### deferred features  
- [ ] Docker containerization and deployment
- [ ] LLM integration for natural language queries
- [ ] Advanced data visualizations
- [ ] SHAP-based model interpretability
- [ ] Comprehensive test suite
- [ ] Model monitoring and retraining pipeline

## ðŸš€ quick start (actual commands)

### backend setup
```bash
# from project root
uv sync
uv run python scripts/generate_synthetic_data.py
uv run python scripts/simple_train.py

# start api server
cd backend
PYTHONPATH=/path/to/project/backend uv run uvicorn app.main:app --reload --port 8000
```

### frontend setup
```bash
cd frontend
pnpm install
pnpm dev
```

### access points
- **frontend**: http://localhost:3000
- **api docs**: http://localhost:8000/docs
- **health check**: http://localhost:8000/api/health/

tags:: #implementation #roadmap #healthcare #ai #development #completed